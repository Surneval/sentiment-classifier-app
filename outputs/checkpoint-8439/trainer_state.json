{
  "best_metric": 0.8736,
  "best_model_checkpoint": "outputs/checkpoint-8439",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8439,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03554923569143263,
      "grad_norm": 1.065711259841919,
      "learning_rate": 4.9407512738476124e-05,
      "loss": 0.6664,
      "step": 100
    },
    {
      "epoch": 0.07109847138286526,
      "grad_norm": 1.761971116065979,
      "learning_rate": 4.8815025476952246e-05,
      "loss": 0.5083,
      "step": 200
    },
    {
      "epoch": 0.10664770707429791,
      "grad_norm": 6.789219856262207,
      "learning_rate": 4.822253821542837e-05,
      "loss": 0.4121,
      "step": 300
    },
    {
      "epoch": 0.14219694276573053,
      "grad_norm": 3.0206944942474365,
      "learning_rate": 4.763005095390449e-05,
      "loss": 0.4153,
      "step": 400
    },
    {
      "epoch": 0.17774617845716317,
      "grad_norm": 3.396831512451172,
      "learning_rate": 4.703756369238061e-05,
      "loss": 0.4122,
      "step": 500
    },
    {
      "epoch": 0.21329541414859582,
      "grad_norm": 2.7252695560455322,
      "learning_rate": 4.644507643085674e-05,
      "loss": 0.386,
      "step": 600
    },
    {
      "epoch": 0.24884464984002844,
      "grad_norm": 2.114238977432251,
      "learning_rate": 4.585258916933286e-05,
      "loss": 0.3881,
      "step": 700
    },
    {
      "epoch": 0.28439388553146105,
      "grad_norm": 2.001030921936035,
      "learning_rate": 4.5260101907808984e-05,
      "loss": 0.3924,
      "step": 800
    },
    {
      "epoch": 0.3199431212228937,
      "grad_norm": 1.9327203035354614,
      "learning_rate": 4.4667614646285106e-05,
      "loss": 0.3862,
      "step": 900
    },
    {
      "epoch": 0.35549235691432635,
      "grad_norm": 1.9757667779922485,
      "learning_rate": 4.407512738476123e-05,
      "loss": 0.3503,
      "step": 1000
    },
    {
      "epoch": 0.391041592605759,
      "grad_norm": 1.7705928087234497,
      "learning_rate": 4.348264012323735e-05,
      "loss": 0.3649,
      "step": 1100
    },
    {
      "epoch": 0.42659082829719164,
      "grad_norm": 3.3921964168548584,
      "learning_rate": 4.289015286171347e-05,
      "loss": 0.3367,
      "step": 1200
    },
    {
      "epoch": 0.46214006398862423,
      "grad_norm": 1.6616226434707642,
      "learning_rate": 4.2297665600189594e-05,
      "loss": 0.3692,
      "step": 1300
    },
    {
      "epoch": 0.4976892996800569,
      "grad_norm": 2.3738794326782227,
      "learning_rate": 4.1705178338665715e-05,
      "loss": 0.3829,
      "step": 1400
    },
    {
      "epoch": 0.5332385353714895,
      "grad_norm": 2.1352994441986084,
      "learning_rate": 4.1112691077141844e-05,
      "loss": 0.365,
      "step": 1500
    },
    {
      "epoch": 0.5687877710629221,
      "grad_norm": 5.47240686416626,
      "learning_rate": 4.0520203815617966e-05,
      "loss": 0.3827,
      "step": 1600
    },
    {
      "epoch": 0.6043370067543548,
      "grad_norm": 3.07891845703125,
      "learning_rate": 3.992771655409409e-05,
      "loss": 0.3612,
      "step": 1700
    },
    {
      "epoch": 0.6398862424457874,
      "grad_norm": 3.800999402999878,
      "learning_rate": 3.9335229292570217e-05,
      "loss": 0.3136,
      "step": 1800
    },
    {
      "epoch": 0.67543547813722,
      "grad_norm": 5.747268199920654,
      "learning_rate": 3.874274203104634e-05,
      "loss": 0.3246,
      "step": 1900
    },
    {
      "epoch": 0.7109847138286527,
      "grad_norm": 1.410581350326538,
      "learning_rate": 3.815025476952246e-05,
      "loss": 0.3733,
      "step": 2000
    },
    {
      "epoch": 0.7465339495200853,
      "grad_norm": 1.3812395334243774,
      "learning_rate": 3.755776750799858e-05,
      "loss": 0.3587,
      "step": 2100
    },
    {
      "epoch": 0.782083185211518,
      "grad_norm": 1.2921792268753052,
      "learning_rate": 3.6965280246474704e-05,
      "loss": 0.3381,
      "step": 2200
    },
    {
      "epoch": 0.8176324209029506,
      "grad_norm": 2.9587032794952393,
      "learning_rate": 3.6372792984950826e-05,
      "loss": 0.3513,
      "step": 2300
    },
    {
      "epoch": 0.8531816565943833,
      "grad_norm": 5.823057174682617,
      "learning_rate": 3.578030572342695e-05,
      "loss": 0.3312,
      "step": 2400
    },
    {
      "epoch": 0.8887308922858158,
      "grad_norm": 3.0825631618499756,
      "learning_rate": 3.518781846190307e-05,
      "loss": 0.3421,
      "step": 2500
    },
    {
      "epoch": 0.9242801279772485,
      "grad_norm": 4.619994163513184,
      "learning_rate": 3.459533120037919e-05,
      "loss": 0.3317,
      "step": 2600
    },
    {
      "epoch": 0.9598293636686811,
      "grad_norm": 2.431737184524536,
      "learning_rate": 3.4002843938855313e-05,
      "loss": 0.3529,
      "step": 2700
    },
    {
      "epoch": 0.9953785993601137,
      "grad_norm": 1.939283847808838,
      "learning_rate": 3.341035667733144e-05,
      "loss": 0.3433,
      "step": 2800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.859,
      "eval_loss": 0.31641897559165955,
      "eval_runtime": 19.9786,
      "eval_samples_per_second": 250.268,
      "eval_steps_per_second": 15.667,
      "step": 2813
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 3.0424416065216064,
      "learning_rate": 3.2817869415807564e-05,
      "loss": 0.3203,
      "step": 2900
    },
    {
      "epoch": 1.066477070742979,
      "grad_norm": 3.6321756839752197,
      "learning_rate": 3.2225382154283686e-05,
      "loss": 0.3267,
      "step": 3000
    },
    {
      "epoch": 1.1020263064344116,
      "grad_norm": 4.674587726593018,
      "learning_rate": 3.163289489275981e-05,
      "loss": 0.343,
      "step": 3100
    },
    {
      "epoch": 1.1375755421258442,
      "grad_norm": 1.6499736309051514,
      "learning_rate": 3.104040763123593e-05,
      "loss": 0.3211,
      "step": 3200
    },
    {
      "epoch": 1.1731247778172769,
      "grad_norm": 1.4186885356903076,
      "learning_rate": 3.044792036971205e-05,
      "loss": 0.3301,
      "step": 3300
    },
    {
      "epoch": 1.2086740135087095,
      "grad_norm": 1.8025964498519897,
      "learning_rate": 2.9855433108188173e-05,
      "loss": 0.3428,
      "step": 3400
    },
    {
      "epoch": 1.2442232492001422,
      "grad_norm": 3.3464365005493164,
      "learning_rate": 2.92629458466643e-05,
      "loss": 0.3175,
      "step": 3500
    },
    {
      "epoch": 1.2797724848915748,
      "grad_norm": 2.1993331909179688,
      "learning_rate": 2.867045858514042e-05,
      "loss": 0.3333,
      "step": 3600
    },
    {
      "epoch": 1.3153217205830074,
      "grad_norm": 4.358217716217041,
      "learning_rate": 2.8077971323616542e-05,
      "loss": 0.3241,
      "step": 3700
    },
    {
      "epoch": 1.35087095627444,
      "grad_norm": 1.4118404388427734,
      "learning_rate": 2.7485484062092664e-05,
      "loss": 0.3463,
      "step": 3800
    },
    {
      "epoch": 1.3864201919658727,
      "grad_norm": 4.839625835418701,
      "learning_rate": 2.6892996800568786e-05,
      "loss": 0.3273,
      "step": 3900
    },
    {
      "epoch": 1.4219694276573054,
      "grad_norm": 1.985244870185852,
      "learning_rate": 2.6300509539044908e-05,
      "loss": 0.3059,
      "step": 4000
    },
    {
      "epoch": 1.457518663348738,
      "grad_norm": 2.9066758155822754,
      "learning_rate": 2.5708022277521033e-05,
      "loss": 0.3231,
      "step": 4100
    },
    {
      "epoch": 1.4930678990401707,
      "grad_norm": 1.6420212984085083,
      "learning_rate": 2.5115535015997155e-05,
      "loss": 0.315,
      "step": 4200
    },
    {
      "epoch": 1.5286171347316033,
      "grad_norm": 2.0648539066314697,
      "learning_rate": 2.452304775447328e-05,
      "loss": 0.3292,
      "step": 4300
    },
    {
      "epoch": 1.564166370423036,
      "grad_norm": 4.249481201171875,
      "learning_rate": 2.3930560492949402e-05,
      "loss": 0.3334,
      "step": 4400
    },
    {
      "epoch": 1.5997156061144686,
      "grad_norm": 1.016071081161499,
      "learning_rate": 2.3338073231425524e-05,
      "loss": 0.3199,
      "step": 4500
    },
    {
      "epoch": 1.6352648418059013,
      "grad_norm": 1.6925100088119507,
      "learning_rate": 2.2745585969901646e-05,
      "loss": 0.3096,
      "step": 4600
    },
    {
      "epoch": 1.670814077497334,
      "grad_norm": 3.0419929027557373,
      "learning_rate": 2.215309870837777e-05,
      "loss": 0.3333,
      "step": 4700
    },
    {
      "epoch": 1.7063633131887666,
      "grad_norm": 5.639978885650635,
      "learning_rate": 2.1560611446853893e-05,
      "loss": 0.3342,
      "step": 4800
    },
    {
      "epoch": 1.7419125488801992,
      "grad_norm": 2.7313549518585205,
      "learning_rate": 2.0968124185330015e-05,
      "loss": 0.3049,
      "step": 4900
    },
    {
      "epoch": 1.7774617845716318,
      "grad_norm": 7.654158115386963,
      "learning_rate": 2.0375636923806137e-05,
      "loss": 0.301,
      "step": 5000
    },
    {
      "epoch": 1.8130110202630645,
      "grad_norm": 2.4410653114318848,
      "learning_rate": 1.9783149662282262e-05,
      "loss": 0.3316,
      "step": 5100
    },
    {
      "epoch": 1.8485602559544971,
      "grad_norm": 5.065030097961426,
      "learning_rate": 1.9190662400758384e-05,
      "loss": 0.3135,
      "step": 5200
    },
    {
      "epoch": 1.8841094916459296,
      "grad_norm": 4.1440510749816895,
      "learning_rate": 1.859817513923451e-05,
      "loss": 0.3384,
      "step": 5300
    },
    {
      "epoch": 1.9196587273373622,
      "grad_norm": 1.571334719657898,
      "learning_rate": 1.800568787771063e-05,
      "loss": 0.3581,
      "step": 5400
    },
    {
      "epoch": 1.9552079630287948,
      "grad_norm": 3.929887294769287,
      "learning_rate": 1.7413200616186753e-05,
      "loss": 0.3131,
      "step": 5500
    },
    {
      "epoch": 1.9907571987202275,
      "grad_norm": 2.7947540283203125,
      "learning_rate": 1.6820713354662875e-05,
      "loss": 0.3067,
      "step": 5600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8702,
      "eval_loss": 0.298868328332901,
      "eval_runtime": 19.0726,
      "eval_samples_per_second": 262.157,
      "eval_steps_per_second": 16.411,
      "step": 5626
    },
    {
      "epoch": 2.0263064344116604,
      "grad_norm": 3.186647653579712,
      "learning_rate": 1.6228226093138997e-05,
      "loss": 0.3168,
      "step": 5700
    },
    {
      "epoch": 2.0618556701030926,
      "grad_norm": 4.019090175628662,
      "learning_rate": 1.5635738831615122e-05,
      "loss": 0.2836,
      "step": 5800
    },
    {
      "epoch": 2.097404905794525,
      "grad_norm": 2.7361409664154053,
      "learning_rate": 1.5043251570091244e-05,
      "loss": 0.3159,
      "step": 5900
    },
    {
      "epoch": 2.132954141485958,
      "grad_norm": 3.434541940689087,
      "learning_rate": 1.4450764308567366e-05,
      "loss": 0.3282,
      "step": 6000
    },
    {
      "epoch": 2.1685033771773905,
      "grad_norm": 4.190479755401611,
      "learning_rate": 1.385827704704349e-05,
      "loss": 0.314,
      "step": 6100
    },
    {
      "epoch": 2.204052612868823,
      "grad_norm": 1.7107661962509155,
      "learning_rate": 1.3265789785519611e-05,
      "loss": 0.3387,
      "step": 6200
    },
    {
      "epoch": 2.239601848560256,
      "grad_norm": 3.325033664703369,
      "learning_rate": 1.2673302523995733e-05,
      "loss": 0.3105,
      "step": 6300
    },
    {
      "epoch": 2.2751510842516884,
      "grad_norm": 2.4053173065185547,
      "learning_rate": 1.2080815262471858e-05,
      "loss": 0.3187,
      "step": 6400
    },
    {
      "epoch": 2.310700319943121,
      "grad_norm": 2.8924992084503174,
      "learning_rate": 1.148832800094798e-05,
      "loss": 0.3052,
      "step": 6500
    },
    {
      "epoch": 2.3462495556345537,
      "grad_norm": 2.0715768337249756,
      "learning_rate": 1.0895840739424102e-05,
      "loss": 0.3057,
      "step": 6600
    },
    {
      "epoch": 2.3817987913259864,
      "grad_norm": 2.346463441848755,
      "learning_rate": 1.0303353477900226e-05,
      "loss": 0.2709,
      "step": 6700
    },
    {
      "epoch": 2.417348027017419,
      "grad_norm": 5.802582263946533,
      "learning_rate": 9.710866216376348e-06,
      "loss": 0.3155,
      "step": 6800
    },
    {
      "epoch": 2.4528972627088517,
      "grad_norm": 4.897604465484619,
      "learning_rate": 9.118378954852471e-06,
      "loss": 0.2855,
      "step": 6900
    },
    {
      "epoch": 2.4884464984002843,
      "grad_norm": 2.8488762378692627,
      "learning_rate": 8.525891693328595e-06,
      "loss": 0.3229,
      "step": 7000
    },
    {
      "epoch": 2.523995734091717,
      "grad_norm": 2.1600306034088135,
      "learning_rate": 7.933404431804717e-06,
      "loss": 0.324,
      "step": 7100
    },
    {
      "epoch": 2.5595449697831496,
      "grad_norm": 4.7725372314453125,
      "learning_rate": 7.340917170280839e-06,
      "loss": 0.3019,
      "step": 7200
    },
    {
      "epoch": 2.5950942054745822,
      "grad_norm": 2.52504301071167,
      "learning_rate": 6.748429908756962e-06,
      "loss": 0.3255,
      "step": 7300
    },
    {
      "epoch": 2.630643441166015,
      "grad_norm": 4.271389961242676,
      "learning_rate": 6.155942647233085e-06,
      "loss": 0.3184,
      "step": 7400
    },
    {
      "epoch": 2.6661926768574475,
      "grad_norm": 5.526976108551025,
      "learning_rate": 5.5634553857092076e-06,
      "loss": 0.293,
      "step": 7500
    },
    {
      "epoch": 2.70174191254888,
      "grad_norm": 3.88299822807312,
      "learning_rate": 4.97096812418533e-06,
      "loss": 0.2871,
      "step": 7600
    },
    {
      "epoch": 2.737291148240313,
      "grad_norm": 4.744258880615234,
      "learning_rate": 4.378480862661453e-06,
      "loss": 0.3193,
      "step": 7700
    },
    {
      "epoch": 2.7728403839317455,
      "grad_norm": 2.5129172801971436,
      "learning_rate": 3.785993601137576e-06,
      "loss": 0.3245,
      "step": 7800
    },
    {
      "epoch": 2.808389619623178,
      "grad_norm": 3.055464506149292,
      "learning_rate": 3.1935063396136985e-06,
      "loss": 0.3236,
      "step": 7900
    },
    {
      "epoch": 2.8439388553146108,
      "grad_norm": 4.145092487335205,
      "learning_rate": 2.601019078089821e-06,
      "loss": 0.3024,
      "step": 8000
    },
    {
      "epoch": 2.8794880910060434,
      "grad_norm": 3.902017831802368,
      "learning_rate": 2.008531816565944e-06,
      "loss": 0.3163,
      "step": 8100
    },
    {
      "epoch": 2.915037326697476,
      "grad_norm": 1.6668821573257446,
      "learning_rate": 1.4160445550420666e-06,
      "loss": 0.3218,
      "step": 8200
    },
    {
      "epoch": 2.9505865623889087,
      "grad_norm": 2.4543251991271973,
      "learning_rate": 8.235572935181894e-07,
      "loss": 0.3118,
      "step": 8300
    },
    {
      "epoch": 2.9861357980803414,
      "grad_norm": 3.247486114501953,
      "learning_rate": 2.3107003199431212e-07,
      "loss": 0.3351,
      "step": 8400
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8736,
      "eval_loss": 0.2972537875175476,
      "eval_runtime": 17.333,
      "eval_samples_per_second": 288.467,
      "eval_steps_per_second": 18.058,
      "step": 8439
    }
  ],
  "logging_steps": 100,
  "max_steps": 8439,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4547454981120000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
